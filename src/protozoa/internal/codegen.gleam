//// Code Generation Module
////
//// This module orchestrates the generation of idiomatic Gleam code from parsed Protocol Buffer
//// definitions. It delegates to specialized sub-modules for different aspects of code generation.

import gleam/list
import gleam/option
import gleam/result
import gleam/string
import protozoa/internal/codegen/decoders
import protozoa/internal/codegen/encoders
import protozoa/internal/codegen/router
import protozoa/internal/codegen/types
import protozoa/internal/type_registry.{type TypeRegistry}
import protozoa/parser.{type Path, type ProtoFile}
import simplifile

/// Generate code for multiple proto files combined into a single proto.gleam file
pub fn generate_combined_proto_file(
  files files: List(Path),
  registry registry: TypeRegistry,
  output_dir output_dir: String,
) -> Result(List(#(String, String)), String) {
  let output_path = output_dir <> "/proto.gleam"

  // Split files into user files and well-known files
  let user_files =
    list.filter(files, fn(file) { !is_well_known_proto_file(file.path) })
  let well_known_files =
    list.filter(files, fn(file) { is_well_known_proto_file(file.path) })

  let combined_header = generate_combined_file_header(user_files)
  let combined_imports = generate_combined_imports(files, registry)

  // Generate content for user files
  use user_sections <- result.try(
    list.try_map(user_files, fn(file_entry) {
      generate_file_content_sections(
        file_entry.content,
        file_entry.path,
        registry,
      )
    }),
  )

  // Generate content for well-known files
  use well_known_sections <- result.try(
    list.try_map(well_known_files, fn(file_entry) {
      generate_file_content_sections(
        file_entry.content,
        file_entry.path,
        registry,
      )
    }),
  )

  // Combine all sections from both user and well-known files
  let all_sections = list.append(user_sections, well_known_sections)
  let combined_sections = combine_content_sections(all_sections)

  let final_code =
    string.join(
      [
        combined_header,
        combined_imports,
        combined_sections.enum_types,
        combined_sections.message_types,
        combined_sections.message_encoders,
        combined_sections.message_decoders,
        combined_sections.enum_helpers,
        combined_sections.service_stubs,
        combined_sections.service_routers,
      ]
        |> list.filter(fn(section) { !string.is_empty(section) }),
      "\n\n",
    )

  use _ <- result.try(
    simplifile.write(output_path, final_code)
    |> result.map_error(fn(_) { "Failed to write file: " <> output_path }),
  )

  Ok([#(output_path, final_code)])
}

/// Generate code for a single proto file
fn generate_combined_file_header(files: List(Path)) -> String {
  let file_list =
    files
    |> list.map(fn(file) { file.path })
    |> string.join(", ")

  "//// Generated by Protozoa from "
  <> file_list
  <> "\n"
  <> "//// \n"
  <> "//// This file is auto-generated and can be safely deleted and regenerated.\n"
  <> "//// To regenerate all proto files, run: gleam run -m protozoa\n"
  <> "//// \n"
  <> "//// DO NOT EDIT THIS FILE MANUALLY - all changes will be lost on regeneration."
}

fn generate_combined_imports(
  files: List(Path),
  _registry: TypeRegistry,
) -> String {
  // Collect all imports needed across all proto files
  let all_needed_imports =
    files
    |> list.fold([], fn(acc, file) {
      let file_imports = determine_needed_imports(file.content)
      list.append(acc, file_imports)
    })
    |> list.unique()
    |> list.sort(string.compare)

  string.join(all_needed_imports, "\n")
}

pub type ContentSections {
  ContentSections(
    enum_types: String,
    message_types: String,
    message_encoders: String,
    message_decoders: String,
    enum_helpers: String,
    service_stubs: String,
    service_routers: String,
  )
}

fn generate_file_content_sections(
  proto_file: ProtoFile,
  file_path: String,
  registry: TypeRegistry,
) -> Result(ContentSections, String) {
  let enum_types = types.generate_enum_types(proto_file.enums)
  let message_types =
    types.generate_types_with_registry(proto_file.messages, registry, file_path)
  let message_encoders =
    encoders.generate_encoders_with_registry(
      proto_file.messages,
      registry,
      file_path,
    )
  let message_decoders =
    decoders.generate_decoders_with_registry(
      proto_file.messages,
      registry,
      file_path,
    )
  let enum_helpers =
    encoders.generate_enum_helpers_with_nested(
      proto_file.enums,
      proto_file.messages,
    )
  let service_stubs = generate_service_stubs(proto_file.services)
  let service_routers =
    proto_file.services
    |> list.map(fn(service) {
      router.generate_service_router(service, proto_file.messages)
    })
    |> list.filter(fn(s) { !string.is_empty(s) })
    |> string.join("\n\n")

  Ok(ContentSections(
    enum_types: enum_types,
    message_types: message_types,
    message_encoders: message_encoders,
    message_decoders: message_decoders,
    enum_helpers: enum_helpers,
    service_stubs: service_stubs,
    service_routers: service_routers,
  ))
}

fn combine_content_sections(
  all_sections: List(ContentSections),
) -> ContentSections {
  list.fold(
    all_sections,
    ContentSections("", "", "", "", "", "", ""),
    fn(acc, section) {
      ContentSections(
        enum_types: combine_non_empty(acc.enum_types, section.enum_types),
        message_types: combine_non_empty(
          acc.message_types,
          section.message_types,
        ),
        message_encoders: combine_non_empty(
          acc.message_encoders,
          section.message_encoders,
        ),
        message_decoders: combine_non_empty(
          acc.message_decoders,
          section.message_decoders,
        ),
        enum_helpers: combine_non_empty(acc.enum_helpers, section.enum_helpers),
        service_stubs: combine_non_empty(
          acc.service_stubs,
          section.service_stubs,
        ),
        service_routers: combine_non_empty(
          acc.service_routers,
          section.service_routers,
        ),
      )
    },
  )
}

fn combine_non_empty(left: String, right: String) -> String {
  case string.is_empty(left), string.is_empty(right) {
    True, True -> ""
    True, False -> right
    False, True -> left
    False, False -> left <> "\n\n" <> right
  }
}

fn is_well_known_proto_file(file_path: String) -> Bool {
  string.contains(file_path, "google/protobuf/")
}

fn determine_needed_imports(proto_file: ProtoFile) -> List(String) {
  let base_imports = ["import protozoa/decode", "import protozoa/encode"]

  // Add list import if we have repeated fields or field masks
  let needs_list =
    has_repeated_fields(proto_file) || has_field_mask_reference(proto_file)
  let imports = case needs_list {
    True -> ["import gleam/list", ..base_imports]
    False -> base_imports
  }

  // Add option import if we have oneofs or optional fields
  let has_optional = has_optional_fields(proto_file)
  let has_oneof = has_oneofs(proto_file)
  let imports = case has_optional || has_oneof {
    True -> ["import gleam/option", ..imports]
    False -> imports
  }

  // Add dict import if we have oneofs (for oneof decoders)
  let needs_dict = has_oneofs(proto_file)
  let imports = case needs_dict {
    True -> ["import gleam/dict", ..imports]
    False -> imports
  }

  // Add result import if we have enum decoders
  let needs_result = has_enums(proto_file) || has_enum_fields(proto_file)
  let imports = case needs_result {
    True -> ["import gleam/result", ..imports]
    False -> imports
  }

  // Add string import if we have enum decoders (for error messages)
  let needs_string = has_enums(proto_file) || has_enum_fields(proto_file)
  let imports = case needs_string {
    True -> ["import gleam/string", ..imports]
    False -> imports
  }

  // Add int import if we have enums (for error messages)
  let needs_int = has_enums(proto_file) || has_enum_fields(proto_file)
  let imports = case needs_int {
    True -> ["import gleam/int", ..imports]
    False -> imports
  }

  // Add wire import if we have messages with bytes fields or message fields
  let needs_wire =
    has_bytes_fields(proto_file) || has_message_fields(proto_file)
  let imports = case needs_wire {
    True -> ["import protozoa/wire", ..imports]
    False -> imports
  }

  // Add imports for HTTP adapters if we have services with HTTP methods
  let has_http_adapters = has_services_with_http_methods(proto_file)
  let imports = case has_http_adapters {
    True -> {
      let base_http_imports = [
        "import gleam/http/request",
        "import gleam/http/response",
        "import gleam/int",
        "import gleam/list",
        "import gleam/string",
        ..imports
      ]

      // Only add float if we have float/double query parameters
      let needs_float = has_float_query_params(proto_file)
      let base_http_imports = case needs_float {
        True -> ["import gleam/float", ..base_http_imports]
        False -> base_http_imports
      }

      base_http_imports
    }
    False -> imports
  }

  list.sort(imports, string.compare)
  |> list.unique()
}

fn has_repeated_fields(proto_file: ProtoFile) -> Bool {
  proto_file.messages
  |> list.any(fn(msg) {
    msg.fields
    |> list.any(fn(field) {
      case field.field_type {
        parser.Repeated(_) -> True
        _ -> False
      }
    })
  })
}

fn has_field_mask_reference(proto_file: ProtoFile) -> Bool {
  get_referenced_well_known_types(proto_file)
  |> list.contains("google.protobuf.FieldMask")
}

fn has_oneofs(proto_file: ProtoFile) -> Bool {
  proto_file.messages
  |> list.any(fn(msg) { !list.is_empty(msg.oneofs) })
}

fn has_optional_fields(proto_file: ProtoFile) -> Bool {
  proto_file.messages
  |> list.any(fn(msg) {
    msg.fields
    |> list.any(fn(field) {
      case field.field_type {
        parser.Optional(_) -> True
        _ -> False
      }
    })
  })
}

fn has_enums(proto_file: ProtoFile) -> Bool {
  !list.is_empty(proto_file.enums)
  || proto_file.messages
  |> list.any(fn(msg) { !list.is_empty(msg.enums) })
}

fn has_enum_fields(proto_file: ProtoFile) -> Bool {
  proto_file.messages
  |> list.any(fn(msg) {
    msg.fields
    |> list.any(fn(field) {
      case field.field_type {
        parser.EnumType(_) -> True
        parser.Repeated(parser.EnumType(_)) -> True
        parser.Optional(parser.EnumType(_)) -> True
        _ -> False
      }
    })
  })
}

fn has_bytes_fields(proto_file: ProtoFile) -> Bool {
  proto_file.messages
  |> list.any(fn(msg) {
    msg.fields
    |> list.any(fn(field) {
      case field.field_type {
        parser.Bytes -> True
        parser.Repeated(parser.Bytes) -> True
        parser.Optional(parser.Bytes) -> True
        _ -> False
      }
    })
  })
}

fn has_message_fields(proto_file: ProtoFile) -> Bool {
  proto_file.messages
  |> list.any(fn(msg) {
    msg.fields
    |> list.any(fn(field) {
      case field.field_type {
        parser.MessageType(_) -> True
        parser.Repeated(parser.MessageType(_)) -> True
        parser.Optional(parser.MessageType(_)) -> True
        _ -> False
      }
    })
    || list.any(msg.oneofs, fn(oneof) {
      list.any(oneof.fields, fn(field) {
        case field.field_type {
          parser.MessageType(_) -> True
          _ -> False
        }
      })
    })
  })
}

fn has_services_with_http_methods(proto_file: ProtoFile) -> Bool {
  proto_file.services
  |> list.any(fn(service) {
    service.methods
    |> list.any(fn(method) {
      case method.http_method, method.http_path {
        option.Some(_), option.Some(_) -> True
        _, _ -> False
      }
    })
  })
}

fn has_float_query_params(proto_file: ProtoFile) -> Bool {
  // Check if any GET/DELETE methods have float/double fields
  proto_file.services
  |> list.any(fn(service) {
    service.methods
    |> list.filter(fn(method) {
      case method.http_method {
        option.Some(parser.Get) | option.Some(parser.Delete) -> True
        _ -> False
      }
    })
    |> list.any(fn(method) {
      // Find the request message for this method
      proto_file.messages
      |> list.find(fn(msg) { msg.name == method.input_type })
      |> result.map(fn(msg) {
        msg.fields
        |> list.any(fn(field) {
          case field.field_type {
            parser.Float | parser.Double -> True
            parser.Repeated(parser.Float) | parser.Repeated(parser.Double) ->
              True
            parser.Optional(parser.Float) | parser.Optional(parser.Double) ->
              True
            _ -> False
          }
        })
      })
      |> result.unwrap(False)
    })
  })
}

fn get_referenced_well_known_types(proto_file: ProtoFile) -> List(String) {
  // Scan all messages for well-known type references
  proto_file.messages
  |> list.fold([], fn(acc, message) {
    let field_types = get_field_well_known_types(message)
    list.append(acc, field_types)
  })
  |> list.unique()
}

fn get_field_well_known_types(message: parser.Message) -> List(String) {
  let field_types =
    message.fields
    |> list.fold([], fn(acc, field) {
      case field.field_type {
        parser.MessageType(name) ->
          case is_well_known_type(name) {
            True -> [name, ..acc]
            False -> acc
          }
        parser.Repeated(parser.MessageType(name)) ->
          case is_well_known_type(name) {
            True -> [name, ..acc]
            False -> acc
          }
        parser.Optional(parser.MessageType(name)) ->
          case is_well_known_type(name) {
            True -> [name, ..acc]
            False -> acc
          }
        _ -> acc
      }
    })

  let oneof_types =
    message.oneofs
    |> list.fold([], fn(acc, oneof) {
      oneof.fields
      |> list.fold(acc, fn(acc2, field) {
        case field.field_type {
          parser.MessageType(name) ->
            case is_well_known_type(name) {
              True -> [name, ..acc2]
              False -> acc2
            }
          _ -> acc2
        }
      })
    })

  list.append(field_types, oneof_types)
}

pub fn is_well_known_type(type_name: String) -> Bool {
  case type_name {
    // Fully qualified names
    "google.protobuf.Timestamp"
    | "google.protobuf.Duration"
    | "google.protobuf.FieldMask"
    | "google.protobuf.Empty"
    | "google.protobuf.Any"
    | "google.protobuf.Struct"
    | "google.protobuf.StringValue"
    | "google.protobuf.Type"
    | "google.protobuf.Field"
    | "google.protobuf.Enum"
    | "google.protobuf.EnumValue"
    | "google.protobuf.Option"
    | "google.protobuf.SourceContext"
    | "google.protobuf.Api"
    | "google.protobuf.Method"
    | "google.protobuf.Mixin"
    | // Flattened names (what the parser might use after resolution)
      "Timestamp"
    | "Duration"
    | "FieldMask"
    | "Empty"
    | "Any"
    | "Struct"
    | "StringValue"
    | "Type"
    | "Field"
    | "Enum"
    | "EnumValue"
    | "Option"
    | "SourceContext"
    | "Api"
    | "Method"
    | "Mixin" -> True
    _ -> False
  }
}

pub fn generate_well_known_type_definition(type_name: String) -> String {
  case type_name {
    // Fully qualified names
    "google.protobuf.Timestamp" | "Timestamp" -> generate_timestamp_definition()
    "google.protobuf.Duration" | "Duration" -> generate_duration_definition()
    "google.protobuf.FieldMask" | "FieldMask" -> generate_fieldmask_definition()
    "google.protobuf.Empty" | "Empty" -> generate_empty_definition()
    "google.protobuf.Any" | "Any" -> generate_any_definition()
    "google.protobuf.Struct" | "Struct" -> generate_struct_definition()
    "google.protobuf.StringValue" | "StringValue" ->
      generate_stringvalue_definition()
    "google.protobuf.Type" | "Type" -> generate_type_definition()
    "google.protobuf.Field" | "Field" -> generate_field_definition()
    "google.protobuf.Enum" | "Enum" -> generate_enum_definition()
    "google.protobuf.EnumValue" | "EnumValue" -> generate_enumvalue_definition()
    "google.protobuf.Option" | "Option" -> generate_option_definition()
    "google.protobuf.SourceContext" | "SourceContext" ->
      generate_sourcecontext_definition()
    "google.protobuf.Api" | "Api" -> generate_api_definition()
    "google.protobuf.Method" | "Method" -> generate_method_definition()
    "google.protobuf.Mixin" | "Mixin" -> generate_mixin_definition()
    _ -> ""
  }
}

fn generate_timestamp_definition() -> String {
  let lines = [
    "pub type Timestamp {",
    "  Timestamp(",
    "    seconds: Int,",
    "    nanos: Int,",
    "  )",
    "}",
    "",
    "pub fn encode_timestamp(timestamp: Timestamp) -> BitArray {",
    "  encode.message([",
    "    encode.int64_field(1, timestamp.seconds),",
    "    encode.int32_field(2, timestamp.nanos),",
    "  ])",
    "}",
    "",
    "pub fn timestamp_decoder() -> decode.Decoder(Timestamp) {",
    "  use seconds <- decode.then(decode.int64_with_default(1, 0))",
    "  use nanos <- decode.then(decode.int32_with_default(2, 0))",
    "  decode.success(Timestamp(seconds: seconds, nanos: nanos))",
    "}",
  ]
  string.join(lines, "\n")
}

fn generate_duration_definition() -> String {
  let lines = [
    "pub type Duration {",
    "  Duration(",
    "    seconds: Int,",
    "    nanos: Int,",
    "  )",
    "}",
    "",
    "pub fn encode_duration(duration: Duration) -> BitArray {",
    "  encode.message([",
    "    encode.int64_field(1, duration.seconds),",
    "    encode.int32_field(2, duration.nanos),",
    "  ])",
    "}",
    "",
    "pub fn duration_decoder() -> decode.Decoder(Duration) {",
    "  use seconds <- decode.then(decode.int64_with_default(1, 0))",
    "  use nanos <- decode.then(decode.int32_with_default(2, 0))",
    "  decode.success(Duration(seconds: seconds, nanos: nanos))",
    "}",
  ]
  string.join(lines, "\n")
}

fn generate_fieldmask_definition() -> String {
  let lines = [
    "pub type FieldMask {",
    "  FieldMask(",
    "    paths: List(String),",
    "  )",
    "}",
    "",
    "pub fn encode_fieldmask(fieldmask: FieldMask) -> BitArray {",
    "  let paths_fields = list.map(fieldmask.paths, fn(v) { encode.string_field(1, v) })",
    "  encode.message(paths_fields)",
    "}",
    "",
    "pub fn fieldmask_decoder() -> decode.Decoder(FieldMask) {",
    "  use paths <- decode.then(decode.repeated_string(1))",
    "  decode.success(FieldMask(paths: paths))",
    "}",
  ]
  string.join(lines, "\n")
}

fn generate_empty_definition() -> String {
  let lines = [
    "pub type Empty {",
    "  Empty",
    "}",
    "",
    "pub fn encode_empty(_empty: Empty) -> BitArray {",
    "  encode.message([])",
    "}",
    "",
    "pub fn empty_decoder() -> decode.Decoder(Empty) {",
    "  decode.success(Empty)",
    "}",
  ]
  string.join(lines, "\n")
}

fn generate_any_definition() -> String {
  let lines = [
    "pub type Any {",
    "  Any(",
    "    type_url: String,",
    "    value: BitArray,",
    "  )",
    "}",
    "",
    "pub fn encode_any(any: Any) -> BitArray {",
    "  encode.message([",
    "    encode.string_field(1, any.type_url),",
    "    encode.field(2, wire.LengthDelimited, encode.length_delimited(any.value)),",
    "  ])",
    "}",
    "",
    "pub fn any_decoder() -> decode.Decoder(Any) {",
    "  use type_url <- decode.then(decode.string_with_default(1, \"\"))",
    "  use value <- decode.then(decode.bytes(2))",
    "  decode.success(Any(type_url: type_url, value: value))",
    "}",
  ]
  string.join(lines, "\n")
}

fn generate_struct_definition() -> String {
  let lines = [
    "pub type NullValue {",
    "  NULL_VALUE",
    "}",
    "",
    "pub type Value {",
    "  NullValueVariant(NullValue)",
    "  NumberValueVariant(Float)",
    "  StringValueVariant(String)",
    "  BoolValueVariant(Bool)",
    "  StructValueVariant(Struct)",
    "  ListValueVariant(ListValue)",
    "}",
    "",
    "pub type ListValue {",
    "  ListValue(values: List(Value))",
    "}",
    "",
    "pub type Struct {",
    "  Struct(fields: dict.Dict(String, Value))",
    "}",
    "",
    "pub fn encode_struct(struct: Struct) -> BitArray {",
    "  encode.message([",
    "    encode.field(1, wire.LengthDelimited, encode_struct_fields_map(struct.fields)),",
    "  ])",
    "}",
    "",
    "fn encode_struct_fields_map(fields: dict.Dict(String, Value)) -> BitArray {",
    "  // Simplified implementation - encode as repeated fields",
    "  encode.length_delimited(<<>>)",
    "}",
    "",
    "pub fn struct_decoder() -> decode.Decoder(Struct) {",
    "  // Simplified implementation - return empty struct",
    "  decode.success(Struct(fields: dict.new()))",
    "}",
    "",
    "fn encode_value(value: Value) -> BitArray {",
    "  case value {",
    "    NullValueVariant(_) -> encode.message([encode.enum_field(1, 0)])",
    "    NumberValueVariant(n) -> encode.message([encode.double_field(2, n)])",
    "    StringValueVariant(s) -> encode.message([encode.string_field(3, s)])",
    "    BoolValueVariant(b) -> encode.message([encode.bool_field(4, b)])",
    "    StructValueVariant(s) -> encode.message([encode.field(5, wire.LengthDelimited, encode_struct(s))])",
    "    ListValueVariant(l) -> encode.message([encode.field(6, wire.LengthDelimited, encode_listvalue(l))])",
    "  }",
    "}",
    "",
    "pub fn encode_listvalue(listvalue: ListValue) -> BitArray {",
    "  encode.message([",
    "    encode.repeated_field(1, listvalue.values, encode_value),",
    "  ])",
    "}",
    "",
    "pub fn value_decoder() -> decode.Decoder(Value) {",
    "  // Simplified implementation - default to null value",
    "  decode.success(NullValueVariant(NULL_VALUE))",
    "}",
  ]
  string.join(lines, "\n")
}

fn generate_stringvalue_definition() -> String {
  let lines = [
    "pub type StringValue {",
    "  StringValue(value: String)",
    "}",
    "",
    "pub fn encode_stringvalue(stringvalue: StringValue) -> BitArray {",
    "  encode.message([",
    "    encode.string_field(1, stringvalue.value),",
    "  ])",
    "}",
    "",
    "pub fn stringvalue_decoder() -> decode.Decoder(StringValue) {",
    "  use value <- decode.then(decode.string_with_default(1, \"\"))",
    "  decode.success(StringValue(value: value))",
    "}",
  ]
  string.join(lines, "\n")
}

/// Generate service stub definitions for gRPC/HTTP services
fn generate_service_stubs(services: List(parser.Service)) -> String {
  case services {
    [] -> ""
    _ -> {
      services
      |> list.map(generate_single_service_stub)
      |> string.join("\n\n")
    }
  }
}

/// Generate stub for a single service
fn generate_single_service_stub(service: parser.Service) -> String {
  let error_type = generate_service_error_type(service.name)

  string.join(
    [
      "// Service: " <> service.name,
      "",
      error_type,
    ],
    "\n",
  )
}

/// Generate a ServiceError type for the service
fn generate_service_error_type(service_name: String) -> String {
  let error_type_name = service_name <> "Error"
  string.join(
    [
      "/// Error type for " <> service_name <> " service",
      "pub type " <> error_type_name <> " {",
      "  NotFound",
      "  Unauthorized",
      "  BadRequest(String)",
      "  InvalidRequest(String)",
      "  InternalError(String)",
      "  Unavailable(String)",
      "}",
    ],
    "\n",
  )
}

// New well-known type definitions

fn generate_type_definition() -> String {
  let lines = [
    "pub type Syntax {",
    "  SYNTAX_PROTO2",
    "  SYNTAX_PROTO3",
    "  SYNTAX_EDITIONS",
    "}",
    "",
    "pub type Type {",
    "  Type(",
    "    name: String,",
    "    fields: List(Field),",
    "    oneofs: List(String),",
    "    options: List(Option),",
    "    source_context: option.Option(SourceContext),",
    "    syntax: Syntax,",
    "    edition: String,",
    "  )",
    "}",
    "",
    "pub fn encode_type(type_def: Type) -> BitArray {",
    "  encode.message([",
    "    encode.string_field(1, type_def.name),",
    "    // Simplified: skip complex nested fields for now",
    "    encode.enum_field(6, encode_syntax_value(type_def.syntax)),",
    "    encode.string_field(7, type_def.edition),",
    "  ])",
    "}",
    "",
    "pub fn type_decoder() -> decode.Decoder(Type) {",
    "  use name <- decode.then(decode.string_with_default(1, \"\"))",
    "  use fields <- decode.then(decode.repeated_field(2, fn(_) { Ok([]) }))",
    "  use oneofs <- decode.then(decode.repeated_string(3))",
    "  use options <- decode.then(decode.repeated_field(4, fn(_) { Ok([]) }))",
    "  use source_context <- decode.then(decode.optional_nested_message(5, sourcecontext_decoder()))",
    "  use syntax <- decode.then(decode.enum_field(6, decode_syntax_field()))",
    "  use edition <- decode.then(decode.string_with_default(7, \"\"))",
    "  decode.success(Type(",
    "    name: name,",
    "    fields: fields,",
    "    oneofs: oneofs,",
    "    options: options,",
    "    source_context: source_context,",
    "    syntax: syntax,",
    "    edition: edition,",
    "  ))",
    "}",
    "",
    "fn encode_syntax_value(syntax: Syntax) -> Int {",
    "  case syntax {",
    "    SYNTAX_PROTO2 -> 0",
    "    SYNTAX_PROTO3 -> 1",
    "    SYNTAX_EDITIONS -> 2",
    "  }",
    "}",
    "",
    "fn decode_syntax_field() -> decode.Decoder(Syntax) {",
    "  decode.field(0, fn(field) {",
    "    use value <- result.try(decode.int32_field(field))",
    "    case value {",
    "      0 -> Ok(SYNTAX_PROTO2)",
    "      1 -> Ok(SYNTAX_PROTO3)",
    "      2 -> Ok(SYNTAX_EDITIONS)",
    "      _ -> Error(decode.DecodeError(expected: \"valid syntax value\", found: \"Unknown syntax value: \" <> string.inspect(value), path: []))",
    "    }",
    "  })",
    "}",
  ]
  string.join(lines, "\n")
}

fn generate_field_definition() -> String {
  let lines = [
    "pub type FieldKind {",
    "  TYPE_UNKNOWN",
    "  TYPE_DOUBLE",
    "  TYPE_FLOAT",
    "  TYPE_INT64",
    "  TYPE_UINT64",
    "  TYPE_INT32",
    "  TYPE_FIXED64",
    "  TYPE_FIXED32",
    "  TYPE_BOOL",
    "  TYPE_STRING",
    "  TYPE_GROUP",
    "  TYPE_MESSAGE",
    "  TYPE_BYTES",
    "  TYPE_UINT32",
    "  TYPE_ENUM",
    "  TYPE_SFIXED32",
    "  TYPE_SFIXED64",
    "  TYPE_SINT32",
    "  TYPE_SINT64",
    "}",
    "",
    "pub type FieldCardinality {",
    "  CARDINALITY_UNKNOWN",
    "  CARDINALITY_OPTIONAL",
    "  CARDINALITY_REQUIRED",
    "  CARDINALITY_REPEATED",
    "}",
    "",
    "pub type Field {",
    "  Field(",
    "    kind: FieldKind,",
    "    cardinality: FieldCardinality,",
    "    number: Int,",
    "    name: String,",
    "    type_url: String,",
    "    oneof_index: Int,",
    "    packed: Bool,",
    "    options: List(Option),",
    "    json_name: String,",
    "    default_value: String,",
    "  )",
    "}",
    "",
    "pub fn encode_field(field: Field) -> BitArray {",
    "  encode.message([",
    "    encode.enum_field(1, encode_fieldkind_value(field.kind)),",
    "    encode.enum_field(2, encode_fieldcardinality_value(field.cardinality)),",
    "    encode.int32_field(3, field.number),",
    "    encode.string_field(4, field.name),",
    "    encode.string_field(6, field.type_url),",
    "    encode.int32_field(7, field.oneof_index),",
    "    encode.bool_field(8, field.packed),",
    "    encode.string_field(10, field.json_name),",
    "    encode.string_field(11, field.default_value),",
    "  ])",
    "}",
    "",
    "pub fn field_decoder() -> decode.Decoder(Field) {",
    "  use kind <- decode.then(decode.enum_field(1, decode_fieldkind_field))",
    "  use cardinality <- decode.then(decode.enum_field(2, decode_fieldcardinality_field))",
    "  use number <- decode.then(decode.int32_with_default(3, 0))",
    "  use name <- decode.then(decode.string_with_default(4, \"\"))",
    "  use type_url <- decode.then(decode.string_with_default(6, \"\"))",
    "  use oneof_index <- decode.then(decode.int32_with_default(7, 0))",
    "  use packed <- decode.then(decode.bool_with_default(8, False))",
    "  use options <- decode.then(decode.repeated_field(9, fn(_) { Ok([]) }))",
    "  use json_name <- decode.then(decode.string_with_default(10, \"\"))",
    "  use default_value <- decode.then(decode.string_with_default(11, \"\"))",
    "  decode.success(Field(",
    "    kind: kind,",
    "    cardinality: cardinality,",
    "    number: number,",
    "    name: name,",
    "    type_url: type_url,",
    "    oneof_index: oneof_index,",
    "    packed: packed,",
    "    options: options,",
    "    json_name: json_name,",
    "    default_value: default_value,",
    "  ))",
    "}",
  ]
  string.join(lines, "\n")
}

fn generate_enum_definition() -> String {
  let lines = [
    "pub type Enum {",
    "  Enum(",
    "    name: String,",
    "    enumvalue: List(EnumValue),",
    "    options: List(Option),",
    "    source_context: option.Option(SourceContext),",
    "    syntax: Syntax,",
    "    edition: String,",
    "  )",
    "}",
    "",
    "pub fn encode_enum(enum_def: Enum) -> BitArray {",
    "  encode.message([",
    "    encode.string_field(1, enum_def.name),",
    "    // Simplified implementation",
    "    encode.enum_field(5, encode_syntax_value(enum_def.syntax)),",
    "    encode.string_field(6, enum_def.edition),",
    "  ])",
    "}",
    "",
    "pub fn enum_decoder() -> decode.Decoder(Enum) {",
    "  use name <- decode.then(decode.string_with_default(1, \"\"))",
    "  use enumvalue <- decode.then(decode.repeated_field(2, fn(_) { Ok([]) }))",
    "  use options <- decode.then(decode.repeated_field(3, fn(_) { Ok([]) }))",
    "  use source_context <- decode.then(decode.optional_nested_message(4, sourcecontext_decoder()))",
    "  use syntax <- decode.then(decode.enum_field(5, decode_syntax_field))",
    "  use edition <- decode.then(decode.string_with_default(6, \"\"))",
    "  decode.success(Enum(",
    "    name: name,",
    "    enumvalue: enumvalue,",
    "    options: options,",
    "    source_context: source_context,",
    "    syntax: syntax,",
    "    edition: edition,",
    "  ))",
    "}",
  ]
  string.join(lines, "\n")
}

fn generate_enumvalue_definition() -> String {
  let lines = [
    "pub type EnumValue {",
    "  EnumValue(",
    "    name: String,",
    "    number: Int,",
    "    options: List(Option),",
    "  )",
    "}",
    "",
    "pub fn encode_enumvalue(enumvalue: EnumValue) -> BitArray {",
    "  encode.message([",
    "    encode.string_field(1, enumvalue.name),",
    "    encode.int32_field(2, enumvalue.number),",
    "  ])",
    "}",
    "",
    "pub fn enumvalue_decoder() -> decode.Decoder(EnumValue) {",
    "  use name <- decode.then(decode.string_with_default(1, \"\"))",
    "  use number <- decode.then(decode.int32_with_default(2, 0))",
    "  use options <- decode.then(decode.repeated_field(3, fn(_) { Ok([]) }))",
    "  decode.success(EnumValue(",
    "    name: name,",
    "    number: number,",
    "    options: options,",
    "  ))",
    "}",
  ]
  string.join(lines, "\n")
}

fn generate_option_definition() -> String {
  let lines = [
    "pub type Option {",
    "  Option(",
    "    name: String,",
    "    value: Any,",
    "  )",
    "}",
    "",
    "pub fn encode_option(option_def: Option) -> BitArray {",
    "  encode.message([",
    "    encode.string_field(1, option_def.name),",
    "    encode.field(2, wire.LengthDelimited, encode_any(option_def.value)),",
    "  ])",
    "}",
    "",
    "pub fn option_decoder() -> decode.Decoder(Option) {",
    "  use name <- decode.then(decode.string_with_default(1, \"\"))",
    "  use value <- decode.then(decode.nested_message(2, any_decoder()))",
    "  decode.success(Option(",
    "    name: name,",
    "    value: value,",
    "  ))",
    "}",
  ]
  string.join(lines, "\n")
}

fn generate_sourcecontext_definition() -> String {
  let lines = [
    "pub type SourceContext {",
    "  SourceContext(",
    "    file_name: String,",
    "  )",
    "}",
    "",
    "pub fn encode_sourcecontext(sourcecontext: SourceContext) -> BitArray {",
    "  encode.message([",
    "    encode.string_field(1, sourcecontext.file_name),",
    "  ])",
    "}",
    "",
    "pub fn sourcecontext_decoder() -> decode.Decoder(SourceContext) {",
    "  use file_name <- decode.then(decode.string_with_default(1, \"\"))",
    "  decode.success(SourceContext(",
    "    file_name: file_name,",
    "  ))",
    "}",
  ]
  string.join(lines, "\n")
}

fn generate_api_definition() -> String {
  let lines = [
    "pub type Api {",
    "  Api(",
    "    name: String,",
    "    methods: List(Method),",
    "    options: List(Option),",
    "    version: String,",
    "    source_context: option.Option(SourceContext),",
    "    mixins: List(Mixin),",
    "    syntax: Syntax,",
    "  )",
    "}",
    "",
    "pub fn encode_api(api: Api) -> BitArray {",
    "  encode.message([",
    "    encode.string_field(1, api.name),",
    "    encode.string_field(4, api.version),",
    "    encode.enum_field(7, encode_syntax_value(api.syntax)),",
    "  ])",
    "}",
    "",
    "pub fn api_decoder() -> decode.Decoder(Api) {",
    "  use name <- decode.then(decode.string_with_default(1, \"\"))",
    "  use methods <- decode.then(decode.repeated_field(2, fn(_) { Ok([]) }))",
    "  use options <- decode.then(decode.repeated_field(3, fn(_) { Ok([]) }))",
    "  use version <- decode.then(decode.string_with_default(4, \"\"))",
    "  use source_context <- decode.then(decode.optional_nested_message(5, sourcecontext_decoder()))",
    "  use mixins <- decode.then(decode.repeated_field(6, fn(_) { Ok([]) }))",
    "  use syntax <- decode.then(decode.enum_field(7, decode_syntax_field))",
    "  decode.success(Api(",
    "    name: name,",
    "    methods: methods,",
    "    options: options,",
    "    version: version,",
    "    source_context: source_context,",
    "    mixins: mixins,",
    "    syntax: syntax,",
    "  ))",
    "}",
  ]
  string.join(lines, "\n")
}

fn generate_method_definition() -> String {
  let lines = [
    "pub type Method {",
    "  Method(",
    "    name: String,",
    "    request_type_url: String,",
    "    request_streaming: Bool,",
    "    response_type_url: String,",
    "    response_streaming: Bool,",
    "    options: List(Option),",
    "    syntax: Syntax,",
    "  )",
    "}",
    "",
    "pub fn encode_method(method: Method) -> BitArray {",
    "  encode.message([",
    "    encode.string_field(1, method.name),",
    "    encode.string_field(2, method.request_type_url),",
    "    encode.bool_field(3, method.request_streaming),",
    "    encode.string_field(4, method.response_type_url),",
    "    encode.bool_field(5, method.response_streaming),",
    "    encode.enum_field(7, encode_syntax_value(method.syntax)),",
    "  ])",
    "}",
    "",
    "pub fn method_decoder() -> decode.Decoder(Method) {",
    "  use name <- decode.then(decode.string_with_default(1, \"\"))",
    "  use request_type_url <- decode.then(decode.string_with_default(2, \"\"))",
    "  use request_streaming <- decode.then(decode.bool_with_default(3, False))",
    "  use response_type_url <- decode.then(decode.string_with_default(4, \"\"))",
    "  use response_streaming <- decode.then(decode.bool_with_default(5, False))",
    "  use options <- decode.then(decode.repeated_field(6, fn(_) { Ok([]) }))",
    "  use syntax <- decode.then(decode.enum_field(7, decode_syntax_field))",
    "  decode.success(Method(",
    "    name: name,",
    "    request_type_url: request_type_url,",
    "    request_streaming: request_streaming,",
    "    response_type_url: response_type_url,",
    "    response_streaming: response_streaming,",
    "    options: options,",
    "    syntax: syntax,",
    "  ))",
    "}",
  ]
  string.join(lines, "\n")
}

fn generate_mixin_definition() -> String {
  let lines = [
    "pub type Mixin {",
    "  Mixin(",
    "    name: String,",
    "    root: String,",
    "  )",
    "}",
    "",
    "pub fn encode_mixin(mixin: Mixin) -> BitArray {",
    "  encode.message([",
    "    encode.string_field(1, mixin.name),",
    "    encode.string_field(2, mixin.root),",
    "  ])",
    "}",
    "",
    "pub fn mixin_decoder() -> decode.Decoder(Mixin) {",
    "  use name <- decode.then(decode.string_with_default(1, \"\"))",
    "  use root <- decode.then(decode.string_with_default(2, \"\"))",
    "  decode.success(Mixin(",
    "    name: name,",
    "    root: root,",
    "  ))",
    "}",
  ]
  string.join(lines, "\n")
}
