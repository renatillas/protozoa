//// Code Generation Module
////
//// This module orchestrates the generation of idiomatic Gleam code from parsed Protocol Buffer
//// definitions. It delegates to specialized sub-modules for different aspects of code generation.

import gleam/list
import gleam/result
import gleam/string
import protozoa/internal/codegen/decoders
import protozoa/internal/codegen/encoders
import protozoa/internal/codegen/types
import protozoa/internal/type_registry.{type TypeRegistry}
import protozoa/parser.{type Path, type ProtoFile}
import simplifile

/// Simple wrapper for testing - generates code for a single proto file without imports
pub fn generate_simple_for_testing(proto_file: ProtoFile) -> String {
  let registry = type_registry.new()
  let fake_file_path = "test.proto"

  case generate_file_with_imports(proto_file, fake_file_path, registry) {
    Ok(code) -> code
    Error(err) -> panic as { "Code generation failed: " <> err }
  }
}

/// Generate code for multiple proto files with cross-file imports
pub fn generate_with_imports(
  files files: List(Path),
  registry registry: TypeRegistry,
  output_dir output_dir: String,
) -> Result(List(#(String, String)), String) {
  list.try_map(files, fn(file_entry) {
    let base_name = get_base_name(file_entry.path)
    let output_path = output_dir <> "/" <> base_name <> ".gleam"

    use code <- result.try(generate_file_with_imports(
      file_entry.content,
      file_entry.path,
      registry,
    ))

    use _ <- result.try(
      simplifile.write(output_path, code)
      |> result.map_error(fn(_) { "Failed to write file: " <> output_path }),
    )

    Ok(#(output_path, code))
  })
}

/// Generate code for a single proto file
fn generate_file_with_imports(
  proto_file: ProtoFile,
  file_path: String,
  registry: TypeRegistry,
) -> Result(String, String) {
  // Generate all components
  let header = generate_file_header(file_path)
  let imports = generate_imports(proto_file)
  let well_known_defs = generate_well_known_definitions(proto_file)
  let enum_types = types.generate_enum_types(proto_file.enums)
  let message_types =
    types.generate_types_with_registry(proto_file.messages, registry, file_path)
  let message_encoders =
    encoders.generate_encoders_with_registry(
      proto_file.messages,
      registry,
      file_path,
    )
  let message_decoders =
    decoders.generate_decoders_with_registry(
      proto_file.messages,
      registry,
      file_path,
    )
  let enum_helpers =
    encoders.generate_enum_helpers_with_nested(
      proto_file.enums,
      proto_file.messages,
    )

  let service_stubs = generate_service_stubs(proto_file.services)

  // Combine all sections with proper spacing
  let sections =
    [
      header,
      imports,
      well_known_defs,
      enum_types,
      message_types,
      message_encoders,
      message_decoders,
      enum_helpers,
      service_stubs,
    ]
    |> list.filter(fn(section) { !string.is_empty(section) })

  Ok(string.join(sections, "\n\n"))
}

// Helper functions

fn get_base_name(file_path: String) -> String {
  file_path
  |> string.split("/")
  |> list.last()
  |> result.unwrap("")
  |> string.split(".")
  |> list.first()
  |> result.unwrap("generated")
}

fn generate_file_header(proto_file_path: String) -> String {
  "//// Generated by Protozoa from "
  <> proto_file_path
  <> "\n"
  <> "//// \n"
  <> "//// This file is auto-generated and can be safely deleted and regenerated.\n"
  <> "//// To regenerate all proto files, run: gleam run -m protozoa\n"
  <> "//// \n"
  <> "//// DO NOT EDIT THIS FILE MANUALLY - all changes will be lost on regeneration."
}

fn generate_imports(proto_file: ProtoFile) -> String {
  let needed_imports = determine_needed_imports(proto_file)
  needed_imports
  |> string.join("\n")
}

fn determine_needed_imports(proto_file: ProtoFile) -> List(String) {
  let base_imports = ["import protozoa/decode", "import protozoa/encode"]

  // Add list import if we have repeated fields or field masks
  let needs_list =
    has_repeated_fields(proto_file) || has_field_mask_reference(proto_file)
  let imports = case needs_list {
    True -> ["import gleam/list", ..base_imports]
    False -> base_imports
  }

  // Add option import if we have oneofs or optional fields
  let has_optional = has_optional_fields(proto_file)
  let has_oneof = has_oneofs(proto_file)
  let imports = case has_optional, has_oneof {
    True, True -> ["import gleam/option.{type Option, None, Some}", ..imports]
    True, False -> ["import gleam/option.{type Option, None, Some}", ..imports]
    False, True -> ["import gleam/option.{None, Some}", ..imports]
    False, False -> imports
  }

  // Add dict import if we have oneofs (for oneof decoders)
  let needs_dict = has_oneofs(proto_file)
  let imports = case needs_dict {
    True -> ["import gleam/dict", ..imports]
    False -> imports
  }

  // Add result import if we have enum decoders
  let needs_result = has_enums(proto_file) || has_enum_fields(proto_file)
  let imports = case needs_result {
    True -> ["import gleam/result", ..imports]
    False -> imports
  }

  // Add string import if we have enum decoders (for error messages)
  let needs_string = has_enums(proto_file) || has_enum_fields(proto_file)
  let imports = case needs_string {
    True -> ["import gleam/string", ..imports]
    False -> imports
  }

  // Add int import if we have enums (for error messages)
  let needs_int = has_enums(proto_file) || has_enum_fields(proto_file)
  let imports = case needs_int {
    True -> ["import gleam/int", ..imports]
    False -> imports
  }

  // Add wire import if we have messages with bytes fields or message fields
  let needs_wire =
    has_bytes_fields(proto_file) || has_message_fields(proto_file)
  let imports = case needs_wire {
    True -> ["import protozoa/wire", ..imports]
    False -> imports
  }

  list.sort(imports, string.compare)
}

fn has_repeated_fields(proto_file: ProtoFile) -> Bool {
  proto_file.messages
  |> list.any(fn(msg) {
    msg.fields
    |> list.any(fn(field) {
      case field.field_type {
        parser.Repeated(_) -> True
        _ -> False
      }
    })
  })
}

fn has_field_mask_reference(proto_file: ProtoFile) -> Bool {
  get_referenced_well_known_types(proto_file)
  |> list.contains("google.protobuf.FieldMask")
}

fn has_oneofs(proto_file: ProtoFile) -> Bool {
  proto_file.messages
  |> list.any(fn(msg) { !list.is_empty(msg.oneofs) })
}

fn has_optional_fields(proto_file: ProtoFile) -> Bool {
  proto_file.messages
  |> list.any(fn(msg) {
    msg.fields
    |> list.any(fn(field) {
      case field.field_type {
        parser.Optional(_) -> True
        _ -> False
      }
    })
  })
}

fn has_enums(proto_file: ProtoFile) -> Bool {
  !list.is_empty(proto_file.enums)
  || proto_file.messages
  |> list.any(fn(msg) { !list.is_empty(msg.enums) })
}

fn has_enum_fields(proto_file: ProtoFile) -> Bool {
  proto_file.messages
  |> list.any(fn(msg) {
    msg.fields
    |> list.any(fn(field) {
      case field.field_type {
        parser.EnumType(_) -> True
        parser.Repeated(parser.EnumType(_)) -> True
        parser.Optional(parser.EnumType(_)) -> True
        _ -> False
      }
    })
  })
}

fn has_bytes_fields(proto_file: ProtoFile) -> Bool {
  proto_file.messages
  |> list.any(fn(msg) {
    msg.fields
    |> list.any(fn(field) {
      case field.field_type {
        parser.Bytes -> True
        parser.Repeated(parser.Bytes) -> True
        parser.Optional(parser.Bytes) -> True
        _ -> False
      }
    })
  })
}

fn has_message_fields(proto_file: ProtoFile) -> Bool {
  proto_file.messages
  |> list.any(fn(msg) {
    msg.fields
    |> list.any(fn(field) {
      case field.field_type {
        parser.MessageType(_) -> True
        parser.Repeated(parser.MessageType(_)) -> True
        parser.Optional(parser.MessageType(_)) -> True
        _ -> False
      }
    })
    || list.any(msg.oneofs, fn(oneof) {
      list.any(oneof.fields, fn(field) {
        case field.field_type {
          parser.MessageType(_) -> True
          _ -> False
        }
      })
    })
  })
}

fn generate_well_known_definitions(proto_file: ProtoFile) -> String {
  let referenced_types = get_referenced_well_known_types(proto_file)

  case referenced_types {
    [] -> ""
    _ -> {
      referenced_types
      |> list.map(generate_well_known_type_definition)
      |> string.join("\n\n")
    }
  }
}

fn get_referenced_well_known_types(proto_file: ProtoFile) -> List(String) {
  // Scan all messages for well-known type references
  proto_file.messages
  |> list.fold([], fn(acc, message) {
    let field_types = get_field_well_known_types(message)
    list.append(acc, field_types)
  })
  |> list.unique()
}

fn get_field_well_known_types(message: parser.Message) -> List(String) {
  let field_types =
    message.fields
    |> list.fold([], fn(acc, field) {
      case field.field_type {
        parser.MessageType(name) ->
          case is_well_known_type(name) {
            True -> [name, ..acc]
            False -> acc
          }
        parser.Repeated(parser.MessageType(name)) ->
          case is_well_known_type(name) {
            True -> [name, ..acc]
            False -> acc
          }
        parser.Optional(parser.MessageType(name)) ->
          case is_well_known_type(name) {
            True -> [name, ..acc]
            False -> acc
          }
        _ -> acc
      }
    })

  let oneof_types =
    message.oneofs
    |> list.fold([], fn(acc, oneof) {
      oneof.fields
      |> list.fold(acc, fn(acc2, field) {
        case field.field_type {
          parser.MessageType(name) ->
            case is_well_known_type(name) {
              True -> [name, ..acc2]
              False -> acc2
            }
          _ -> acc2
        }
      })
    })

  list.append(field_types, oneof_types)
}

fn is_well_known_type(type_name: String) -> Bool {
  case type_name {
    "google.protobuf.Timestamp"
    | "google.protobuf.Duration"
    | "google.protobuf.FieldMask"
    | "google.protobuf.Empty"
    | "google.protobuf.Any" -> True
    _ -> False
  }
}

fn generate_well_known_type_definition(type_name: String) -> String {
  case type_name {
    "google.protobuf.Timestamp" -> generate_timestamp_definition()
    "google.protobuf.Duration" -> generate_duration_definition()
    "google.protobuf.FieldMask" -> generate_fieldmask_definition()
    "google.protobuf.Empty" -> generate_empty_definition()
    "google.protobuf.Any" -> generate_any_definition()
    _ -> ""
  }
}

fn generate_timestamp_definition() -> String {
  let lines = [
    "pub type Timestamp {",
    "  Timestamp(",
    "    seconds: Int,",
    "    nanos: Int,",
    "  )",
    "}",
    "",
    "pub fn encode_timestamp(timestamp: Timestamp) -> BitArray {",
    "  encode.message([",
    "    encode.int64_field(1, timestamp.seconds),",
    "    encode.int32_field(2, timestamp.nanos),",
    "  ])",
    "}",
    "",
    "pub fn timestamp_decoder() -> decode.Decoder(Timestamp) {",
    "  use seconds <- decode.then(decode.int64_with_default(1, 0))",
    "  use nanos <- decode.then(decode.int32_with_default(2, 0))",
    "  decode.success(Timestamp(seconds: seconds, nanos: nanos))",
    "}",
  ]
  string.join(lines, "\n")
}

fn generate_duration_definition() -> String {
  let lines = [
    "pub type Duration {",
    "  Duration(",
    "    seconds: Int,",
    "    nanos: Int,",
    "  )",
    "}",
    "",
    "pub fn encode_duration(duration: Duration) -> BitArray {",
    "  encode.message([",
    "    encode.int64_field(1, duration.seconds),",
    "    encode.int32_field(2, duration.nanos),",
    "  ])",
    "}",
    "",
    "pub fn duration_decoder() -> decode.Decoder(Duration) {",
    "  use seconds <- decode.then(decode.int64_with_default(1, 0))",
    "  use nanos <- decode.then(decode.int32_with_default(2, 0))",
    "  decode.success(Duration(seconds: seconds, nanos: nanos))",
    "}",
  ]
  string.join(lines, "\n")
}

fn generate_fieldmask_definition() -> String {
  let lines = [
    "pub type FieldMask {",
    "  FieldMask(",
    "    paths: List(String),",
    "  )",
    "}",
    "",
    "pub fn encode_fieldmask(fieldmask: FieldMask) -> BitArray {",
    "  let paths_fields = list.map(fieldmask.paths, fn(v) { encode.string_field(1, v) })",
    "  encode.message(paths_fields)",
    "}",
    "",
    "pub fn fieldmask_decoder() -> decode.Decoder(FieldMask) {",
    "  use paths <- decode.then(decode.repeated_string(1))",
    "  decode.success(FieldMask(paths: paths))",
    "}",
  ]
  string.join(lines, "\n")
}

fn generate_empty_definition() -> String {
  let lines = [
    "pub type Empty {",
    "  Empty",
    "}",
    "",
    "pub fn encode_empty(_empty: Empty) -> BitArray {",
    "  encode.message([])",
    "}",
    "",
    "pub fn empty_decoder() -> decode.Decoder(Empty) {",
    "  decode.success(Empty)",
    "}",
  ]
  string.join(lines, "\n")
}

fn generate_any_definition() -> String {
  let lines = [
    "pub type Any {",
    "  Any(",
    "    type_url: String,",
    "    value: BitArray,",
    "  )",
    "}",
    "",
    "pub fn encode_any(any: Any) -> BitArray {",
    "  encode.message([",
    "    encode.string_field(1, any.type_url),",
    "    encode.field(2, wire.LengthDelimited, encode.length_delimited(any.value)),",
    "  ])",
    "}",
    "",
    "pub fn any_decoder() -> decode.Decoder(Any) {",
    "  use type_url <- decode.then(decode.string_with_default(1, \"\"))",
    "  use value <- decode.then(decode.bytes(2))",
    "  decode.success(Any(type_url: type_url, value: value))",
    "}",
  ]
  string.join(lines, "\n")
}

/// Generate service stub definitions for gRPC/HTTP services
fn generate_service_stubs(services: List(parser.Service)) -> String {
  case services {
    [] -> ""
    _ -> {
      services
      |> list.map(generate_single_service_stub)
      |> string.join("\n\n")
    }
  }
}

/// Generate stub for a single service
fn generate_single_service_stub(service: parser.Service) -> String {
  let client_interface = generate_client_interface(service)
  let server_interface = generate_server_interface(service)

  string.join(
    [
      "// Service: " <> service.name,
      "",
      client_interface,
      "",
      server_interface,
    ],
    "\n",
  )
}

/// Generate client interface for service
fn generate_client_interface(service: parser.Service) -> String {
  let type_name = service.name <> "Client"
  let method_comments = generate_method_comments(service.methods, "client")

  string.join(
    [
      "/// Client interface for " <> service.name <> " service",
      "/// This trait defines the client-side methods for calling the service",
      "pub type " <> type_name <> " {",
      "  " <> type_name <> "(",
      "    // TODO: Add client implementation fields (e.g., HTTP client, endpoint URL)",
      "    endpoint: String,",
      "  )",
      "}",
      "",
      method_comments,
      "// TODO: Implement actual client method calls",
    ],
    "\n",
  )
}

/// Generate server interface for service
fn generate_server_interface(service: parser.Service) -> String {
  let type_name = service.name <> "Server"
  let method_comments = generate_method_comments(service.methods, "server")

  string.join(
    [
      "/// Server interface for " <> service.name <> " service",
      "/// Implement this trait to handle incoming service requests",
      "pub type " <> type_name <> " {",
      "  " <> type_name <> "(",
      "    // TODO: Add server implementation fields",
      "  )",
      "}",
      "",
      method_comments,
      "// TODO: Implement server method handlers and request routing",
    ],
    "\n",
  )
}

/// Generate method signature comments
fn generate_method_comments(
  methods: List(parser.Method),
  interface_type: String,
) -> String {
  let comment_prefix = case interface_type {
    "client" -> "// Method signatures for " <> interface_type <> ":"
    "server" -> "// Method signatures for " <> interface_type <> ":"
    _ -> "// Method signatures:"
  }

  let method_lines =
    list.map(methods, fn(method) {
      let streaming_info =
        get_streaming_comment(
          method.client_streaming,
          method.server_streaming,
          interface_type,
        )
      "  // "
      <> method.name
      <> "("
      <> method.input_type
      <> ") -> "
      <> method.output_type
      <> " "
      <> streaming_info
    })

  string.join([comment_prefix, ..method_lines], "\n")
}

/// Get streaming type comment for method
fn get_streaming_comment(
  client_streaming: Bool,
  server_streaming: Bool,
  interface_type: String,
) -> String {
  let base_type = case interface_type {
    "server" ->
      "// "
      <> case client_streaming, server_streaming {
        False, False -> "Unary handler"
        False, True -> "Server streaming handler"
        True, False -> "Client streaming handler"
        True, True -> "Bidirectional streaming handler"
      }
    _ ->
      "// "
      <> case client_streaming, server_streaming {
        False, False -> "Unary call"
        False, True -> "Server streaming"
        True, False -> "Client streaming"
        True, True -> "Bidirectional streaming"
      }
  }
  base_type
}
