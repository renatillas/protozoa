//// Code Generation Module
////
//// This module orchestrates the generation of idiomatic Gleam code from parsed Protocol Buffer
//// definitions. It delegates to specialized sub-modules for different aspects of code generation.

import gleam/list
import gleam/result
import gleam/string
import protozoa/internal/codegen/decoders
import protozoa/internal/codegen/encoders
import protozoa/internal/codegen/types
import protozoa/internal/type_registry.{type TypeRegistry}
import protozoa/parser.{type Path, type ProtoFile}
import simplifile

/// Simple wrapper for testing - generates code for a single proto file without imports
pub fn generate_simple_for_testing(proto_file: ProtoFile) -> String {
  let registry = type_registry.new()
  let fake_file_path = "test.proto"

  case generate_file_with_imports(proto_file, fake_file_path, registry) {
    Ok(code) -> code
    Error(err) -> panic as { "Code generation failed: " <> err }
  }
}

/// Generate code for multiple proto files with cross-file imports
pub fn generate_with_imports(
  files files: List(Path),
  registry registry: TypeRegistry,
  output_dir output_dir: String,
) -> Result(List(#(String, String)), String) {
  list.try_map(files, fn(file_entry) {
    let base_name = get_base_name(file_entry.path)
    let output_path = output_dir <> "/" <> base_name <> ".gleam"

    use code <- result.try(generate_file_with_imports(
      file_entry.content,
      file_entry.path,
      registry,
    ))

    use _ <- result.try(
      simplifile.write(output_path, code)
      |> result.map_error(fn(_) { "Failed to write file: " <> output_path }),
    )

    Ok(#(output_path, code))
  })
}

/// Generate code for a single proto file
fn generate_file_with_imports(
  proto_file: ProtoFile,
  file_path: String,
  registry: TypeRegistry,
) -> Result(String, String) {
  // Generate all components
  let header = generate_file_header(file_path)
  let imports = generate_imports(proto_file)
  let well_known_defs = generate_well_known_definitions(proto_file)
  let enum_types = types.generate_enum_types(proto_file.enums)
  let message_types =
    types.generate_types_with_registry(proto_file.messages, registry, file_path)
  let message_encoders =
    encoders.generate_encoders_with_registry(
      proto_file.messages,
      registry,
      file_path,
    )
  let message_decoders =
    decoders.generate_decoders_with_registry(
      proto_file.messages,
      registry,
      file_path,
    )
  let enum_helpers =
    encoders.generate_enum_helpers_with_nested(
      proto_file.enums,
      proto_file.messages,
    )

  // Combine all sections with proper spacing
  let sections =
    [
      header,
      imports,
      well_known_defs,
      enum_types,
      message_types,
      message_encoders,
      message_decoders,
      enum_helpers,
    ]
    |> list.filter(fn(section) { !string.is_empty(section) })

  Ok(string.join(sections, "\n\n"))
}

// Helper functions

fn get_base_name(file_path: String) -> String {
  file_path
  |> string.split("/")
  |> list.last()
  |> result.unwrap("")
  |> string.split(".")
  |> list.first()
  |> result.unwrap("generated")
}

fn generate_file_header(proto_file_path: String) -> String {
  "//// Generated by Protozoa from "
  <> proto_file_path
  <> "\n"
  <> "//// \n"
  <> "//// This file is auto-generated and can be safely deleted and regenerated.\n"
  <> "//// To regenerate all proto files, run: gleam run -m protozoa\n"
  <> "//// \n"
  <> "//// DO NOT EDIT THIS FILE MANUALLY - all changes will be lost on regeneration."
}

fn generate_imports(proto_file: ProtoFile) -> String {
  let needed_imports = determine_needed_imports(proto_file)
  needed_imports
  |> string.join("\n")
}

fn determine_needed_imports(proto_file: ProtoFile) -> List(String) {
  let base_imports = ["import protozoa/decode", "import protozoa/encode"]

  // Add list import if we have repeated fields or field masks
  let needs_list =
    has_repeated_fields(proto_file) || has_field_mask_reference(proto_file)
  let imports = case needs_list {
    True -> ["import gleam/list", ..base_imports]
    False -> base_imports
  }

  // Add option import if we have oneofs or optional fields
  let has_optional = has_optional_fields(proto_file)
  let has_oneof = has_oneofs(proto_file)
  let imports = case has_optional, has_oneof {
    True, True -> ["import gleam/option.{type Option, None, Some}", ..imports]
    True, False -> ["import gleam/option.{type Option, None, Some}", ..imports]
    False, True -> ["import gleam/option.{None, Some}", ..imports]
    False, False -> imports
  }

  // Add dict import if we have oneofs (for oneof decoders)
  let needs_dict = has_oneofs(proto_file)
  let imports = case needs_dict {
    True -> ["import gleam/dict", ..imports]
    False -> imports
  }

  // Add result import if we have enum decoders
  let needs_result = has_enums(proto_file) || has_enum_fields(proto_file)
  let imports = case needs_result {
    True -> ["import gleam/result", ..imports]
    False -> imports
  }

  // Add string import if we have enum decoders (for error messages)
  let needs_string = has_enums(proto_file) || has_enum_fields(proto_file)
  let imports = case needs_string {
    True -> ["import gleam/string", ..imports]
    False -> imports
  }

  // Add int import if we have enums (for error messages)
  let needs_int = has_enums(proto_file) || has_enum_fields(proto_file)
  let imports = case needs_int {
    True -> ["import gleam/int", ..imports]
    False -> imports
  }

  // Add wire import if we have messages with bytes fields or message fields
  let needs_wire =
    has_bytes_fields(proto_file) || has_message_fields(proto_file)
  let imports = case needs_wire {
    True -> ["import protozoa/wire", ..imports]
    False -> imports
  }

  list.sort(imports, string.compare)
}

fn has_repeated_fields(proto_file: ProtoFile) -> Bool {
  proto_file.messages
  |> list.any(fn(msg) {
    msg.fields
    |> list.any(fn(field) {
      case field.field_type {
        parser.Repeated(_) -> True
        _ -> False
      }
    })
  })
}

fn has_field_mask_reference(proto_file: ProtoFile) -> Bool {
  get_referenced_well_known_types(proto_file)
  |> list.contains("google.protobuf.FieldMask")
}

fn has_oneofs(proto_file: ProtoFile) -> Bool {
  proto_file.messages
  |> list.any(fn(msg) { !list.is_empty(msg.oneofs) })
}

fn has_optional_fields(proto_file: ProtoFile) -> Bool {
  proto_file.messages
  |> list.any(fn(msg) {
    msg.fields
    |> list.any(fn(field) {
      case field.field_type {
        parser.Optional(_) -> True
        _ -> False
      }
    })
  })
}

fn has_enums(proto_file: ProtoFile) -> Bool {
  !list.is_empty(proto_file.enums)
  || proto_file.messages
  |> list.any(fn(msg) { !list.is_empty(msg.enums) })
}

fn has_enum_fields(proto_file: ProtoFile) -> Bool {
  proto_file.messages
  |> list.any(fn(msg) {
    msg.fields
    |> list.any(fn(field) {
      case field.field_type {
        parser.EnumType(_) -> True
        parser.Repeated(parser.EnumType(_)) -> True
        parser.Optional(parser.EnumType(_)) -> True
        _ -> False
      }
    })
  })
}

fn has_bytes_fields(proto_file: ProtoFile) -> Bool {
  proto_file.messages
  |> list.any(fn(msg) {
    msg.fields
    |> list.any(fn(field) {
      case field.field_type {
        parser.Bytes -> True
        parser.Repeated(parser.Bytes) -> True
        parser.Optional(parser.Bytes) -> True
        _ -> False
      }
    })
  })
}

fn has_message_fields(proto_file: ProtoFile) -> Bool {
  proto_file.messages
  |> list.any(fn(msg) {
    msg.fields
    |> list.any(fn(field) {
      case field.field_type {
        parser.MessageType(_) -> True
        parser.Repeated(parser.MessageType(_)) -> True
        parser.Optional(parser.MessageType(_)) -> True
        _ -> False
      }
    })
    || list.any(msg.oneofs, fn(oneof) {
      list.any(oneof.fields, fn(field) {
        case field.field_type {
          parser.MessageType(_) -> True
          _ -> False
        }
      })
    })
  })
}

fn generate_well_known_definitions(proto_file: ProtoFile) -> String {
  let referenced_types = get_referenced_well_known_types(proto_file)

  case referenced_types {
    [] -> ""
    _ -> {
      referenced_types
      |> list.map(generate_well_known_type_definition)
      |> string.join("\n\n")
    }
  }
}

fn get_referenced_well_known_types(proto_file: ProtoFile) -> List(String) {
  // Scan all messages for well-known type references
  proto_file.messages
  |> list.fold([], fn(acc, message) {
    let field_types = get_field_well_known_types(message)
    list.append(acc, field_types)
  })
  |> list.unique()
}

fn get_field_well_known_types(message: parser.Message) -> List(String) {
  let field_types =
    message.fields
    |> list.fold([], fn(acc, field) {
      case field.field_type {
        parser.MessageType(name) ->
          case is_well_known_type(name) {
            True -> [name, ..acc]
            False -> acc
          }
        parser.Repeated(parser.MessageType(name)) ->
          case is_well_known_type(name) {
            True -> [name, ..acc]
            False -> acc
          }
        parser.Optional(parser.MessageType(name)) ->
          case is_well_known_type(name) {
            True -> [name, ..acc]
            False -> acc
          }
        _ -> acc
      }
    })

  let oneof_types =
    message.oneofs
    |> list.fold([], fn(acc, oneof) {
      oneof.fields
      |> list.fold(acc, fn(acc2, field) {
        case field.field_type {
          parser.MessageType(name) ->
            case is_well_known_type(name) {
              True -> [name, ..acc2]
              False -> acc2
            }
          _ -> acc2
        }
      })
    })

  list.append(field_types, oneof_types)
}

fn is_well_known_type(type_name: String) -> Bool {
  case type_name {
    "google.protobuf.Timestamp"
    | "google.protobuf.Duration"
    | "google.protobuf.FieldMask"
    | "google.protobuf.Empty"
    | "google.protobuf.Any" -> True
    _ -> False
  }
}

fn generate_well_known_type_definition(type_name: String) -> String {
  case type_name {
    "google.protobuf.Timestamp" -> generate_timestamp_definition()
    "google.protobuf.Duration" -> generate_duration_definition()
    "google.protobuf.FieldMask" -> generate_fieldmask_definition()
    "google.protobuf.Empty" -> generate_empty_definition()
    "google.protobuf.Any" -> generate_any_definition()
    _ -> ""
  }
}

fn generate_timestamp_definition() -> String {
  let lines = [
    "pub type Timestamp {",
    "  Timestamp(",
    "    seconds: Int,",
    "    nanos: Int,",
    "  )",
    "}",
    "",
    "pub fn encode_timestamp(timestamp: Timestamp) -> BitArray {",
    "  encode.message([",
    "    encode.int64_field(1, timestamp.seconds),",
    "    encode.int32_field(2, timestamp.nanos),",
    "  ])",
    "}",
    "",
    "pub fn timestamp_decoder() -> decode.Decoder(Timestamp) {",
    "  use seconds <- decode.then(decode.int64_with_default(1, 0))",
    "  use nanos <- decode.then(decode.int32_with_default(2, 0))",
    "  decode.success(Timestamp(seconds: seconds, nanos: nanos))",
    "}",
  ]
  string.join(lines, "\n")
}

fn generate_duration_definition() -> String {
  let lines = [
    "pub type Duration {",
    "  Duration(",
    "    seconds: Int,",
    "    nanos: Int,",
    "  )",
    "}",
    "",
    "pub fn encode_duration(duration: Duration) -> BitArray {",
    "  encode.message([",
    "    encode.int64_field(1, duration.seconds),",
    "    encode.int32_field(2, duration.nanos),",
    "  ])",
    "}",
    "",
    "pub fn duration_decoder() -> decode.Decoder(Duration) {",
    "  use seconds <- decode.then(decode.int64_with_default(1, 0))",
    "  use nanos <- decode.then(decode.int32_with_default(2, 0))",
    "  decode.success(Duration(seconds: seconds, nanos: nanos))",
    "}",
  ]
  string.join(lines, "\n")
}

fn generate_fieldmask_definition() -> String {
  let lines = [
    "pub type FieldMask {",
    "  FieldMask(",
    "    paths: List(String),",
    "  )",
    "}",
    "",
    "pub fn encode_fieldmask(fieldmask: FieldMask) -> BitArray {",
    "  let paths_fields = list.map(fieldmask.paths, fn(v) { encode.string_field(1, v) })",
    "  encode.message(paths_fields)",
    "}",
    "",
    "pub fn fieldmask_decoder() -> decode.Decoder(FieldMask) {",
    "  use paths <- decode.then(decode.repeated_string(1))",
    "  decode.success(FieldMask(paths: paths))",
    "}",
  ]
  string.join(lines, "\n")
}

fn generate_empty_definition() -> String {
  let lines = [
    "pub type Empty {",
    "  Empty",
    "}",
    "",
    "pub fn encode_empty(_empty: Empty) -> BitArray {",
    "  encode.message([])",
    "}",
    "",
    "pub fn empty_decoder() -> decode.Decoder(Empty) {",
    "  decode.success(Empty)",
    "}",
  ]
  string.join(lines, "\n")
}

fn generate_any_definition() -> String {
  let lines = [
    "pub type Any {",
    "  Any(",
    "    type_url: String,",
    "    value: BitArray,",
    "  )",
    "}",
    "",
    "pub fn encode_any(any: Any) -> BitArray {",
    "  encode.message([",
    "    encode.string_field(1, any.type_url),",
    "    encode.field(2, wire.LengthDelimited, encode.length_delimited(any.value)),",
    "  ])",
    "}",
    "",
    "pub fn any_decoder() -> decode.Decoder(Any) {",
    "  use type_url <- decode.then(decode.string_with_default(1, \"\"))",
    "  use value <- decode.then(decode.bytes(2))",
    "  decode.success(Any(type_url: type_url, value: value))",
    "}",
  ]
  string.join(lines, "\n")
}
